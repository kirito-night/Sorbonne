{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZzLUr_l_Wfb"
      },
      "source": [
        "# TP 1 et 2 : Accès aux données avec index \n",
        "SAM, sujet pour étudiants\n",
        "\n",
        "date de modification : 30/01/2023 19h\n",
        "\n",
        "NOM: \n",
        "\n",
        "Prénom:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TJrAm4JFr9V"
      },
      "source": [
        "Objectifs:\n",
        "Savoir organiser des données en pages pour permettre de modifier un tuple en ne modifiant qu'une seule page.\n",
        "\n",
        "Comprendre les méthodes d'accès suivantes :\n",
        "\n",
        "*   Lecture séquentielle d'une fichier : \"table access full\"\n",
        "*   Lecture d'un tuple dont on connait le rowid : \"table access by index rowid\"\n",
        "*   Opération de sélection par lecture séquentielle et filtrage \n",
        "\n",
        "Comprendre les méthodes d'indexation :\n",
        "\n",
        "*   Créer un index\n",
        "*   Opération de Sélection par index et lecture par rowid\n",
        "\n",
        "Mise à jour de données\n",
        "*   Sélectionner un tuple et modifier un de ses attributs\n",
        "*   Modifier l'index en conséquence lorsque l'attibut modifié est indexé\n",
        "\n",
        "Persistence\n",
        "*   Stocker un index (dans plusieurs pages) pour le reconstruire plus rapidement\n",
        "*   Adapter en conséquence les opérations de modification de l'index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aodlGU01gLqK",
        "outputId": "bf2e77d6-9818-44f9-c296-38797c7a49ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nom de la table : T\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil as sh\n",
        "import numpy as np\n",
        "import random\n",
        "from random import choice\n",
        "from string import ascii_lowercase\n",
        "import time\n",
        "\n",
        "# le nom de la table \n",
        "TABLE = \"T\"\n",
        "print(\"nom de la table :\", TABLE)\n",
        "\n",
        "\n",
        "# le nom du fichier qui contient les données de la table\n",
        "def nom_fichier(table):\n",
        "    return table + \".csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRKX2fgx_gYT"
      },
      "source": [
        "# Générer un fichier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezxoKUCxtASX"
      },
      "source": [
        "Création du fichier contenant un exemple de données.\n",
        "Ce sont des données au format csv. On suppose que chaque ligne correspond à un tuple d'une table **T** ayant *n* attributs :\n",
        "\n",
        "$$ T (a_0, a_1, a_2, ..., a_{n-1})$$\n",
        "\n",
        "Le premier attribut $a_0$ est unique\n",
        "\n",
        "Les attributs suivants ne sont pas uniques (ils ont des doublons). Pour l'attribut $a_1$, il y a en moyenne 2 tuples par valeur, pour $a_2$ il y a en moyenne 4 tuples par valeurs, etc. \n",
        "\n",
        "Les attributs sont des nombres entiers sauf le dernier qui est une chaine de caractères.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIvmnhsTryK4",
        "outputId": "d2657554-d88b-4f0c-bc82-0868273c4ad6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "données créées dans le fichier : T.csv\n"
          ]
        }
      ],
      "source": [
        "# dure environ 40s pour 5M lignes\n",
        "\n",
        "nb_lines = 5 * 1000 * 1000\n",
        "nb_attributes = 7\n",
        "\n",
        "longueur_dernier_attribut = 100\n",
        "# attribut_chaine_caracteres = \"\".join(choice(ascii_lowercase) for i in range(longueur_dernier_attribut))\n",
        "attribut_chaine_caracteres = ''.join('-' for i in range(longueur_dernier_attribut))\n",
        "# print(\"le dernier attribut de chaque tuple est la chaine de caracètes :\", attribut_chaine_caracteres)\n",
        "\n",
        "nb_valeurs_distinctes = nb_lines\n",
        "\n",
        "\n",
        "# le premier attribut est unique\n",
        "a = [random.sample(range(nb_valeurs_distinctes), nb_lines)]\n",
        "\n",
        "# les attributs suivants ont des domaines plus petits\n",
        "for i in range(1, nb_attributes):\n",
        "  nb_valeurs_distinctes = max(2, int(nb_valeurs_distinctes / 2))\n",
        "  a.append(np.random.randint(0, nb_valeurs_distinctes, nb_lines))\n",
        "\n",
        "# on concatène \"verticalement\" les colonnes pour former les tuples.\n",
        "# Le dernier attribut est une chaine de caractères\n",
        "b = [ ','.join(map(lambda x: str(x), e)) + f\",{attribut_chaine_caracteres}\\n\" for e in zip(*a)]\n",
        "\n",
        "# on stocke les données dans un fichier\n",
        "fichier = nom_fichier(TABLE)\n",
        "with open(fichier, \"w\") as f:\n",
        "  f.write(''.join(b))\n",
        "\n",
        "print(\"données créées dans le fichier :\", fichier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogkKxanaBHQF"
      },
      "source": [
        "On affiche le début et la fin du fichier et son nombre de lignes ( = card(T))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aMC3Y6yryK-",
        "outputId": "828ade35-bf19-4404-f8ef-3738e7e03dc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "debut de T.csv :\n",
            "1087658,1839187,147440,173456,147966,126413,16579,----------------------------------------------------------------------------------------------------\n",
            "2574866,670173,232346,590288,297699,23463,50667,----------------------------------------------------------------------------------------------------\n",
            "\n",
            "fin de T.csv : \n",
            "2640202,1433758,631633,62625,254194,23457,11501,----------------------------------------------------------------------------------------------------\n",
            "4676988,1210022,332129,298665,188051,148049,22245,----------------------------------------------------------------------------------------------------\n",
            "\n",
            "size (lines) :\n",
            " 5000000 T.csv\n"
          ]
        }
      ],
      "source": [
        "%%bash -s \"$fichier\"\n",
        "echo \"debut de $1 :\"\n",
        "head -n 2 $1\n",
        "echo\n",
        "echo \"fin de $1 : \"\n",
        "tail -n 2 $1\n",
        "echo\n",
        "echo \"size (lines) :\"\n",
        "wc -l $1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gm8_3CY_odp"
      },
      "source": [
        "# Lecture séquentielle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZaYoqeiHO2p"
      },
      "source": [
        "On définit un *iterateur* pour lire séquentiellement chaque ligne de la table stockée entièrement dans un seul fichier. Le mot python *yield* facilite la définition d'un itérateur.\n",
        "\n",
        "Cet itérateur est invoqué pour lire la table et appliquer un filtre.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSX2XxLx_tBa",
        "outputId": "1cd4779c-7314-4b62-eef1-32c0509bb89e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valeur recherchée : 26717\n",
            "ligne 1323588 : 26717,38528,543877,223032,188559,68582,74152,----------------------------------------------------------------------------------------------------\n",
            "done in 2.579 s\n"
          ]
        }
      ],
      "source": [
        "def lecture_sequentielle(table):\n",
        "  fichier = nom_fichier(table)\n",
        "  with open(fichier, \"r\") as f:\n",
        "    for i, line in enumerate(f):\n",
        "      yield i, line\n",
        "\n",
        "def filtrer_table(table, valeur_recherchee):\n",
        "  for i, line in lecture_sequentielle(table):\n",
        "      a = int(line.split(',')[0])\n",
        "      if a == valeur_recherchee :\n",
        "        print(f\"ligne {i} :\", line.strip())\n",
        "\n",
        "\n",
        "\n",
        "s = np.random.randint(nb_valeurs_distinctes)\n",
        "print(\"valeur recherchée :\", s)\n",
        "\n",
        "t1 = time.time()\n",
        "filtrer_table(TABLE, s)\n",
        "print(\"done in\", round(time.time() - t1, 3), \"s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlmFE3aZTBWC"
      },
      "source": [
        "# Découper une table en pages\n",
        "\n",
        "On organise les données en pages. \n",
        "Pour faciliter le TP, chaque page est représentée par un \"petit\" fichier mais en réalité une page serait un bloc d'un fichier.\n",
        "\n",
        "Dans la suite du TP, on accédera toujours aux pages.\n",
        "Le fichier créé initialement, contenant tous les tuples, ne sera plus utilisé."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOEddKG8PHDF",
        "outputId": "5e63ab9b-7eb8-4741-bc3c-2959cb820ca8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "les pages sont stockées dans le dossier T_pages\n",
            "nb pages créées : 5000\n"
          ]
        }
      ],
      "source": [
        "def page_dir_name(table):\n",
        "  return table + \"_pages\"\n",
        "\n",
        "print(\"les pages sont stockées dans le dossier\", page_dir_name(TABLE) )\n",
        "\n",
        "def decoupe_table_en_pages(table, nb_tuple_par_page):\n",
        "  page_dir = page_dir_name(table)\n",
        "\n",
        "  # vider le dossier qui contiendra les pages\n",
        "  if(os.path.exists(page_dir)):\n",
        "    sh.rmtree(page_dir)\n",
        "  os.makedirs(page_dir, exist_ok=True)\n",
        "\n",
        "  # lire le fichier contenant tous les tuples\n",
        "  p=0\n",
        "  lines = []\n",
        "  for i, line in lecture_sequentielle(table):\n",
        "    lines.append(line)\n",
        "    if (i+1) % nb_tuple_par_page == 0:\n",
        "      \n",
        "      # créer une page\n",
        "      p += 1\n",
        "      with open(page_dir + f\"/page{p}\", \"w\") as fp:\n",
        "        fp.write(''.join(lines))\n",
        "      lines = []\n",
        "\n",
        "  # créer une dernière page, si nécessaire\n",
        "  if len(lines) > 0:\n",
        "    p +=1\n",
        "    with open(page_dir + f\"/page{p}\", \"w\") as fp:\n",
        "        fp.write(''.join(lines))\n",
        "\n",
        "  print(\"nb pages créées :\", p)\n",
        "\n",
        "\n",
        "decoupe_table_en_pages(TABLE, nb_tuple_par_page=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqaml72_bXkj"
      },
      "source": [
        "Afficher le nombre de tuples dans une page (pour quelques pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEX48QWEClJD",
        "outputId": "6e329731-4ac9-4030-ec24-4fb32097692b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    1000 T_pages/page1\n",
            "    1000 T_pages/page10\n",
            "    1000 T_pages/page100\n"
          ]
        }
      ],
      "source": [
        "%%bash -s \"$TABLE\"\n",
        "wc -l $1_pages/* | head -n 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4XDZAmbcUQb"
      },
      "source": [
        "# Lecture séquentielle d'une table découpée en pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fPVOrVpKccUG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valeur recherchée : 49716\n",
            "ligne 196 de la page 1823 : ['49716', '570805', '48952', '456324', '162161', '118998', '62200', '----------------------------------------------------------------------------------------------------']\n",
            "done in 4.27 s\n"
          ]
        }
      ],
      "source": [
        "def lecture_sequentielle_par_page(fichier):\n",
        "    page_dir = page_dir_name(fichier)\n",
        "    nb_pages = len(os.listdir(page_dir))\n",
        "    for p in range(1, nb_pages+1):\n",
        "        with open(page_dir + f\"/page{p}\", \"r\") as fp:\n",
        "            for i, line in enumerate(fp):\n",
        "                yield (p, i, line.strip().split(','))\n",
        "\n",
        "#   # a faire : pour chaque page, lire ses lignes\n",
        "#   # une ligne devient un tuple\n",
        "#   # retourner un itérateur contenant le numéro de page, la position dans la page et le tuple\n",
        "\n",
        "\n",
        "def filtrer_fichier_par_pages(fichier, valeur_recherchee):\n",
        "    for p, i, t in lecture_sequentielle_par_page(fichier):\n",
        "        if int(t[0]) == valeur_recherchee:\n",
        "            print(f\"ligne {i} de la page {p} :\", t)\n",
        "\n",
        "#   # a faire pour chaque (numéro de page, position dans la page, tuple) obtnenu en invoquan la méthode ci dessus\n",
        "#   # convertir le 1er attribut en un nombre l'afficher si il est egal à la valeur recherchee\n",
        "\n",
        "\n",
        "\n",
        "s = np.random.randint(nb_valeurs_distinctes)\n",
        "print(\"valeur recherchée :\", s)\n",
        "\n",
        "t1 = time.time()\n",
        "filtrer_fichier_par_pages(TABLE, s)\n",
        "print(\"done in\", round(time.time() - t1, 2), \"s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcmdLaQ5ruBJ"
      },
      "source": [
        "# Lecture d'un tuple dans une page"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow_RkbQ_U8qs"
      },
      "source": [
        "Cette fonction retourne un tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "F4tYi4xCrxFG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['2459885', '1235056', '303104', '497097', '181005', '70196', '45941', '----------------------------------------------------------------------------------------------------']\n",
            "done in 6.7 ms\n"
          ]
        }
      ],
      "source": [
        "def lecture_tuple(fichier, num_page, position):\n",
        "    with open(page_dir_name(fichier) + f\"/page{num_page}\", \"r\") as fp:\n",
        "        for i, line in enumerate(fp):\n",
        "            if i == position:\n",
        "                return line.strip().split(',')\n",
        "\n",
        "t1 = time.time()\n",
        "print(lecture_tuple(TABLE, 123, 456))\n",
        "print(\"done in\", round((time.time() - t1)*1000, 1), \"ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mD_xZjLxXLD"
      },
      "source": [
        "# Créer un index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNgxRQtOTwOH"
      },
      "source": [
        "## Créer un index unique pour l'attribut $a_0$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCJyftyiXyFo"
      },
      "source": [
        "On sait que $a_0$ est unique. \n",
        "Une entrée associe une *clé* à une *valeur*.\n",
        "*   La *clé* est la valeur du 1er attribut. \n",
        "*   La *valeur* est un **rowid** formé des informations (page, position)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Fhy4IJ0bxWHD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 9.392 s\n",
            "[1087658, 2574866, 3037689, 2268189, 893430, 2599899, 1323497, 1711437, 4990034, 1233758]\n"
          ]
        }
      ],
      "source": [
        "def creation_index_unique(fichier):\n",
        "    index = {}\n",
        "    for p, i, t in lecture_sequentielle_par_page(fichier):\n",
        "        index[int(t[0])] = (p, i)\n",
        "        \n",
        "\n",
        "    # la clé est la valeur du 1er attribut\n",
        "    # la valeur est un rowid composé de (page, position)\n",
        "\n",
        "    return index\n",
        "\n",
        "\n",
        "t1 = time.time()\n",
        "INDEX_UNIQUE_a0 = creation_index_unique(TABLE)\n",
        "print(\"done in\", round(time.time() - t1, 3), \"s\")\n",
        "print(list(INDEX_UNIQUE_a0.keys())[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "r1H4RAlCvBA3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "26273 (3521, 21)\n"
          ]
        }
      ],
      "source": [
        "#vérifier l'index unique\n",
        "s = np.random.randint(nb_valeurs_distinctes)\n",
        "print(s, INDEX_UNIQUE_a0[s])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcUQ8XRcT1dg"
      },
      "source": [
        "## Créer un index non unique pour l'attribut $a_i$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4AtpJouWSmB"
      },
      "source": [
        "On donne un nom de table et le numéro $i$ de l'attribut $a_i$ de la table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gxJC1-m-VRC5"
      },
      "outputs": [],
      "source": [
        "def creation_index(fichier,att):\n",
        "    # creation index qui ne sont pas unique avec table d'hachage\n",
        "    index = {}\n",
        "    for p, i, t in lecture_sequentielle_par_page(fichier):\n",
        "        if t[att] not in index:\n",
        "            index[int(t[att])] = []\n",
        "        index[int(t[att])].append((p, i))\n",
        "\n",
        "\n",
        "\n",
        "t1 = time.time()\n",
        "INDEX_a2 = creation_index(TABLE, 2)\n",
        "print(\"done in\", round(time.time() - t1, 3), \"s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Jd4PJ75JvESP"
      },
      "outputs": [],
      "source": [
        "#vérifier l'index\n",
        "s = np.random.randint(nb_valeurs_distinctes/4)\n",
        "print(\"valeur recherchée :\", s)\n",
        "for r in INDEX_a2[s]:\n",
        "  print(r)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qA7hCef5Kfa"
      },
      "source": [
        "# Accès par index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0zrHPfGJjzm"
      },
      "source": [
        "## Accès ciblé \n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EEEUaCYqhIaB"
      },
      "source": [
        "### Index unique scan. \n",
        "Accès pour rechercher le tuple dont l'attribut indexé a une valeur donnée (on suppose que l'attribut est unique)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PH3f5bz-5JTu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valeur recherchée : 52913\n",
            "['52913', '2056324', '693921', '414452', '131719', '14314', '65245', '----------------------------------------------------------------------------------------------------']\n",
            "done in 3.21 ms\n"
          ]
        }
      ],
      "source": [
        "def acces_par_index_unique(index_unique, table, valeur_recherchee):\n",
        "    if valeur_recherchee in index_unique:\n",
        "        p, i = index_unique[valeur_recherchee]\n",
        "        print(lecture_tuple(table, p, i))\n",
        "    else:\n",
        "        print(\"valeur inexistante\")\n",
        "\n",
        "\n",
        "s = np.random.randint(nb_valeurs_distinctes)\n",
        "print(\"valeur recherchée :\", s)\n",
        "\n",
        "t1 = time.time()\n",
        "acces_par_index_unique(INDEX_UNIQUE_a0, TABLE, s)\n",
        "print(\"done in\", round((time.time() - t1)*1000, 2), \"ms\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xfR_0QAShCJi"
      },
      "source": [
        "### Index scan\n",
        "Accès pour rechercher les tuples dont l'attribut indexé a une valeur donnée. On suppose que l'attribut n'est pas unique et que plusieurs tuples sont retrouvés"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4eyjynk_hZer"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valeur recherchée : 20861\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'INDEX_a2' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/nightsky_kirito/Documents/Sorbonne/M1_DAC/S2/SAM/TME/v2_TP_1_et_2_2023_index_fichier_ETU.ipynb Cell 35\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nightsky_kirito/Documents/Sorbonne/M1_DAC/S2/SAM/TME/v2_TP_1_et_2_2023_index_fichier_ETU.ipynb#X46sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mvaleur recherchée :\u001b[39m\u001b[39m\"\u001b[39m, s)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nightsky_kirito/Documents/Sorbonne/M1_DAC/S2/SAM/TME/v2_TP_1_et_2_2023_index_fichier_ETU.ipynb#X46sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m t1 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nightsky_kirito/Documents/Sorbonne/M1_DAC/S2/SAM/TME/v2_TP_1_et_2_2023_index_fichier_ETU.ipynb#X46sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m acces_par_index(INDEX_a2, TABLE, s)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nightsky_kirito/Documents/Sorbonne/M1_DAC/S2/SAM/TME/v2_TP_1_et_2_2023_index_fichier_ETU.ipynb#X46sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mdone in\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mround\u001b[39m((time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m t1)\u001b[39m*\u001b[39m\u001b[39m1000\u001b[39m, \u001b[39m2\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39mms\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'INDEX_a2' is not defined"
          ]
        }
      ],
      "source": [
        "def acces_par_index(index, table, valeur_recherchee):\n",
        "    if valeur_recherchee in index:\n",
        "        for p, i in index[valeur_recherchee]:\n",
        "            print(lecture_tuple(table, p, i))\n",
        "    else:\n",
        "        print(\"valeur inexistante\")\n",
        "\n",
        "\n",
        "s = np.random.randint(nb_valeurs_distinctes)\n",
        "print(\"valeur recherchée :\", s)\n",
        "\n",
        "t1 = time.time()\n",
        "acces_par_index(INDEX_a2, TABLE, s)\n",
        "print(\"done in\", round((time.time() - t1)*1000, 2), \"ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afvN2LWhJs0V"
      },
      "source": [
        "## Accès par intervalle \n",
        "Index range scan\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIL6jrUuaPMO"
      },
      "source": [
        "### Accès par intervalle sur un attribut unique\n",
        "Accès pour rechercher les tuples dont l'attribut indexé est unique et a une valeur comprise dans un intervalle donné."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "EGEO1PheSEdT"
      },
      "outputs": [],
      "source": [
        "# def acces_intervalle_par_index_unique(index_unique, table, fichier, borne_inf, borne_sup):\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# s = np.random.randint(nb_valeurs_distinctes/4)\n",
        "# print(\"valeur recherchée :\", s)\n",
        "\n",
        "# t1 = time.time()\n",
        "# acces_intervalle_par_index_unique(INDEX_a2, TABLE, s)\n",
        "# print(\"done in\", round(time.time() - t1, 2), \"s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDaG7WelaQrG"
      },
      "source": [
        "### Accès par intervalle sur un attribut NON unique\n",
        "Accès pour rechercher les tuples dont l'attribut indexé n'est **pas** unique et a une valeur comprise dans un intervalle donné."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KQEYfcoEak5A"
      },
      "outputs": [],
      "source": [
        "# def acces_intervalle_par_index(index, table, fichier, borne_inf, borne_sup):\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# s = np.random.randint(nb_valeurs_distinctes / 4)\n",
        "# print(\"valeur recherchée :\", s)\n",
        "\n",
        "# t1 = time.time()\n",
        "# acces_intervalle_par_index(INDEX_a2, TABLE, s)\n",
        "# print(\"done in\", round(time.time() - t1, 2), \"s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Rjm99DrKR8t"
      },
      "source": [
        "#Mise à jour de données\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7np5NI8OKK6z"
      },
      "source": [
        "## Sélectionner un tuple et modifier un de ses attributs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7aN87BOuEbq"
      },
      "source": [
        "### Modification d'un seul tuple\n",
        "\n",
        "On donne une valeur *v* de l'attribut clé $a_0$. Ajouter 1 à l'attribut $a_1$. Cela correspond à l'instruction\n",
        "\n",
        "update T\n",
        "set a1 = a1+1\n",
        "where a0 = *v*\n",
        "\n",
        "Après la modification, accéder aux données pour vérifier que le tuple a bien été modifié. Par exemple, invoquer la fonction\n",
        "acces_par_index_unique(index, table, v)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RCRwCGlwKlEK"
      },
      "outputs": [],
      "source": [
        "# def incremente(index, table):\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdexpmRuKfs2"
      },
      "source": [
        "### Modification de plusieurs tuples\n",
        "\n",
        "On donne une valeur *v* de l'attribut $a_2$ qui n'est pas unique. Ajouter 1 à l'attribut $a_3$.\n",
        "\n",
        "update T set a3 = a3+1 where a1=v\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_18vhvxM61d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zAZws5_KaL8"
      },
      "source": [
        "##Modifier l'index en conséquence lorsque l'attibut modifié est indexé\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_dcGN_dKaya"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as_W7xmOKc3l"
      },
      "source": [
        "# Persistence\n",
        "\n",
        "Dans cette partie, on veut rendre les index persistents en les stockant dans des pages. Cela permet d'utiliser les index plus efficacement sans les recréer entièrement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy8NE3x5KgLj"
      },
      "source": [
        "## Stockage d'un index unique\n",
        "\n",
        "Proposer une solution pour stocker les entrées triées d'un index unique dans plusieurs pages avec une taille de page fixée (500 entrées par page,  soit 500 clés + 500 rowid)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqSClCOgKl6a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aKuhJaDloKO"
      },
      "source": [
        "## Stockage d'un index non unique\n",
        "Proposer une solution pour stocker les entrées triées d'un index non unique dans plusieurs pages avec une taille de page fixée. Dans une page, le total du nombre  de clés + le nombre de rowid ne peut pas dépasser 1000."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzDPXcGzKjKU"
      },
      "source": [
        "## Adapter en conséquence les opérations de modification de l'index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9mXqJeFKmUE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
