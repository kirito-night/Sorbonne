{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vZzLUr_l_Wfb"
      },
      "source": [
        "# SAM: TP1 Accès aux données avec index \n",
        "\n",
        "Sujet pour étudiants\n",
        "\n",
        "date de modification : 26/01/2023 16h\n",
        "\n",
        "NOM: Zeng\n",
        "\n",
        "Prénom: Fanxiang"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TJrAm4JFr9V"
      },
      "source": [
        "Objectifs:\n",
        "Savoir organiser des données en pages pour permettre de modifier un tuple en ne modifiant qu'une seule page.\n",
        "\n",
        "Comprendre les méthodes d'accès suivantes :\n",
        "\n",
        "*   Lecture séquentielle d'une fichier : \"table access full\"\n",
        "*   Lecture d'un tuple dont on connait le rowid : \"table access by index rowid\"\n",
        "*   Opération de sélection par lecture séquentielle et filtrage \n",
        "\n",
        "Comprendre les méthodes d'indexation :\n",
        "\n",
        "*   Créer un index\n",
        "*   Opération de Sélection par index et lecture par rowid\n",
        "\n",
        "Mise à jour de données\n",
        "*   Sélectionner un tuple et modifier un de ses attributs\n",
        "*   Modifier l'index en conséquence lorsque l'attibut modifié est indexé\n",
        "\n",
        "Persistence\n",
        "*   Stocker un index (dans plusieurs pages) pour le reconstruire plus rapidement\n",
        "*   Adapter en conséquence les opérations de modification de l'index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aodlGU01gLqK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil as sh\n",
        "import numpy as np\n",
        "import random\n",
        "from random import choice\n",
        "from string import ascii_lowercase\n",
        "import time\n",
        "\n",
        "DATA = \"data.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRKX2fgx_gYT"
      },
      "source": [
        "# Générer un fichier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezxoKUCxtASX"
      },
      "source": [
        "Création du fichier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TIvmnhsTryK4"
      },
      "outputs": [],
      "source": [
        "# dure environ 40s pour 5M lignes\n",
        "\n",
        "nb_lines = 5 * 1000 * 1000\n",
        "# nb_lines = 100\n",
        "nb_attributes = 7\n",
        "\n",
        "longueur_attribut = 100\n",
        "# string_val = \"\".join(choice(ascii_lowercase) for i in range(longueur_attribut))\n",
        "long_string = ''.join('-' for i in range(longueur_attribut))\n",
        "\n",
        "# a=[np.random.randint(0, int(nb_lines/(10**i)), nb_lines) for i in range(nb_attributes)]\n",
        "nb_valeurs_distinctes = nb_lines\n",
        "\n",
        "# le premier attribut est unique\n",
        "a = [random.sample(range(nb_valeurs_distinctes), nb_lines)]\n",
        "\n",
        "# les attributs suivants ont des domaines plus petits\n",
        "for i in range(1, nb_attributes):\n",
        "  nb_valeurs_distinctes = max(2, int(nb_valeurs_distinctes / 2))\n",
        "  a.append(np.random.randint(0, nb_valeurs_distinctes, nb_lines))\n",
        "\n",
        "b = [ ','.join(map(lambda x: str(x), e)) + f\",{long_string}\\n\" for e in zip(*a)]\n",
        "\n",
        "with open(DATA, \"w\") as f:\n",
        "  f.write(''.join(b))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1aMC3Y6yryK-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "head : \n",
            "668325,375775,777175,199793,91868,1263,53883,----------------------------------------------------------------------------------------------------\n",
            "2883814,1775781,529105,365072,38246,126521,53449,----------------------------------------------------------------------------------------------------\n",
            "tail : \n",
            "1934621,1808134,838894,20873,70264,150259,24485,----------------------------------------------------------------------------------------------------\n",
            "4904763,1423918,61818,585894,74440,75926,30931,----------------------------------------------------------------------------------------------------\n",
            "size (lines) :\n",
            " 5000000 data.csv\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "echo \"head : \"\n",
        "head -n 2 data.csv\n",
        "echo \"tail : \"\n",
        "tail -n 2 data.csv\n",
        "echo \"size (lines) :\"\n",
        "wc -l data.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gm8_3CY_odp"
      },
      "source": [
        "# Lecture séquentielle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nSX2XxLx_tBa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valeur recherchée : 12413\n",
            "ligne 1719411 : 12413,1149164,862575,486975,172155,7809,53812,----------------------------------------------------------------------------------------------------\n",
            "done in 2.0054519176483154 s\n"
          ]
        }
      ],
      "source": [
        "def filtrer_fichier(fichier, valeur_recherchee):\n",
        "  with open(fichier, \"r\") as f:\n",
        "    for i, line in enumerate(f):\n",
        "      a = int(line.split(',')[0])\n",
        "      if a == s :\n",
        "        print(f\"ligne {i} :\", line.strip())\n",
        "\n",
        "\n",
        "s = np.random.randint(nb_valeurs_distinctes)\n",
        "print(\"valeur recherchée :\", s)\n",
        "\n",
        "t1 = time.time()\n",
        "filtrer_fichier(DATA, s)\n",
        "print(\"done in\", time.time() - t1, \"s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlmFE3aZTBWC"
      },
      "source": [
        "# Découper le fichier en pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kOEddKG8PHDF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pages dans : data_pages\n",
            "nb pages créées : 5000\n"
          ]
        }
      ],
      "source": [
        "def page_dir_name(fichier):\n",
        "  return fichier.split('.')[0] + \"_pages\"\n",
        "\n",
        "def decoupe_fichier_en_pages(fichier, nb_tuple_par_page):\n",
        "  page_dir = page_dir_name(fichier)\n",
        "  print(\"pages dans :\", page_dir)\n",
        "  if(os.path.exists(page_dir)):\n",
        "    sh.rmtree(page_dir)\n",
        "  os.makedirs(page_dir, exist_ok=True)\n",
        "\n",
        "  with open(fichier, \"r\") as f:\n",
        "    p=0\n",
        "    lines = []\n",
        "    for i, line in enumerate(f):\n",
        "      lines.append(line)\n",
        "      if (i+1) % nb_tuple_par_page == 0:\n",
        "        p += 1\n",
        "        with open(page_dir + f\"/page{p}\", \"w\") as fp:\n",
        "          fp.write(''.join(lines))\n",
        "        lines = []\n",
        "    if len(lines) > 0:\n",
        "      p +=1\n",
        "      with open(page_dir + f\"/page{p}\", \"w\") as fp:\n",
        "          fp.write(''.join(lines))\n",
        "    \n",
        "    print(\"nb pages créées :\", p)\n",
        "\n",
        "decoupe_fichier_en_pages(DATA, nb_tuple_par_page=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqaml72_bXkj"
      },
      "source": [
        "Afficher le nombre de tuples dans une page (pour quelques pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qEX48QWEClJD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    1000 data_pages/page1\n",
            "    1000 data_pages/page10\n",
            "    1000 data_pages/page100\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "wc -l data_pages/* | head -n 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4XDZAmbcUQb"
      },
      "source": [
        "# Lecture séquentielle du fichier découpé en pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fPVOrVpKccUG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valeur recherchée : 43973\n",
            "ligne 409 de la page 3959 : ['43973', '369671', '1054476', '9150', '124715', '82616', '65703', '----------------------------------------------------------------------------------------------------']\n",
            "done in 3.12 s\n"
          ]
        }
      ],
      "source": [
        "def lecture_sequentielle_par_page(fichier):\n",
        "    page_dir = page_dir_name(fichier)\n",
        "    nb_pages = len(os.listdir(page_dir))\n",
        "    for p in range(1, nb_pages+1):\n",
        "        with open(page_dir + f\"/page{p}\", \"r\") as fp:\n",
        "            for i, line in enumerate(fp):\n",
        "                yield (p, i, line.strip().split(','))\n",
        "\n",
        "#   # a faire : pour chaque page, lire ses lignes\n",
        "#   # une ligne devient un tuple\n",
        "#   # retourner un itérateur contenant le numéro de page, la position dans la page et le tuple\n",
        "\n",
        "\n",
        "def filtrer_fichier_par_pages(fichier, valeur_recherchee):\n",
        "    for p, i, t in lecture_sequentielle_par_page(fichier):\n",
        "        if int(t[0]) == valeur_recherchee:\n",
        "            print(f\"ligne {i} de la page {p} :\", t)\n",
        "\n",
        "#   # a faire pour chaque (numéro de page, position dans la page, tuple) obtnenu en invoquan la méthode ci dessus\n",
        "#   # convertir le 1er attribut en un nombre l'afficher si il est egal à la valeur recherchee\n",
        "\n",
        "\n",
        "\n",
        "s = np.random.randint(nb_valeurs_distinctes)\n",
        "print(\"valeur recherchée :\", s)\n",
        "\n",
        "t1 = time.time()\n",
        "filtrer_fichier_par_pages(\"data.csv\", s)\n",
        "print(\"done in\", round(time.time() - t1, 2), \"s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcmdLaQ5ruBJ"
      },
      "source": [
        "# Lecture d'un tuple dans une page"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "F4tYi4xCrxFG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['4894680', '1142830', '886340', '295680', '116071', '28847', '1282', '----------------------------------------------------------------------------------------------------']\n"
          ]
        }
      ],
      "source": [
        "def lecture_tuple(fichier, num_page, position):\n",
        "    with open(page_dir_name(fichier) + f\"/page{num_page}\", \"r\") as fp:\n",
        "        for i, line in enumerate(fp):\n",
        "            if i == position:\n",
        "                return line.strip().split(',')\n",
        "            \n",
        "tp = lecture_tuple(DATA, 3240, 822)    \n",
        "print(tp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mD_xZjLxXLD"
      },
      "source": [
        "# Créer un index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Fhy4IJ0bxWHD"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'lecture_sequentielle_par_page' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [3], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[39mreturn\u001b[39;00m index\n\u001b[1;32m     13\u001b[0m t1 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 14\u001b[0m index1 \u001b[39m=\u001b[39m creation_index_unique(\u001b[39m\"\u001b[39m\u001b[39mdata.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[39m#print(index1)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mdone in\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mround\u001b[39m(time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m t1, \u001b[39m2\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn [3], line 3\u001b[0m, in \u001b[0;36mcreation_index_unique\u001b[0;34m(fichier)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreation_index_unique\u001b[39m(fichier):\n\u001b[1;32m      2\u001b[0m     index \u001b[39m=\u001b[39m {}\n\u001b[0;32m----> 3\u001b[0m     \u001b[39mfor\u001b[39;00m p, i, t \u001b[39min\u001b[39;00m lecture_sequentielle_par_page(fichier):\n\u001b[1;32m      4\u001b[0m         index[t[\u001b[39m0\u001b[39m]] \u001b[39m=\u001b[39m (p, i)\n\u001b[1;32m      7\u001b[0m     \u001b[39m# la clé est la valeur du 1er attribut\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[39m# la valeur est un rowid composé de (page, position)\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'lecture_sequentielle_par_page' is not defined"
          ]
        }
      ],
      "source": [
        "def creation_index_unique(fichier):\n",
        "    index = {}\n",
        "    for p, i, t in lecture_sequentielle_par_page(fichier):\n",
        "        index[t[0]] = (p, i)\n",
        "        \n",
        "\n",
        "    # la clé est la valeur du 1er attribut\n",
        "    # la valeur est un rowid composé de (page, position)\n",
        "\n",
        "    return index\n",
        "\n",
        "\n",
        "t1 = time.time()\n",
        "index1 = creation_index_unique(\"data.csv\")\n",
        "#print(index1)\n",
        "print(\"done in\", round(time.time() - t1, 2), \"s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def creation_index(fichier,att):\n",
        "    # creation index qui ne sont pas unique avec table d'hachage\n",
        "    index = {}\n",
        "    for p, i, t in lecture_sequentielle_par_page(fichier):\n",
        "        if t[att] not in index:\n",
        "            index[t[att]] = []\n",
        "        index[t[att]].append((p, i))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qA7hCef5Kfa"
      },
      "source": [
        "# Accès par index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0zrHPfGJjzm"
      },
      "source": [
        "## Index unique scan\n",
        "Accès pour rechercher les tuples dont le 1er attribut a une valeur donnée.\n",
        "\n",
        "On peut supposer pour simplifier que l'attribut est unique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PH3f5bz-5JTu"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['75417',\n",
              " '2048217',\n",
              " '714575',\n",
              " '538520',\n",
              " '208272',\n",
              " '75171',\n",
              " '59860',\n",
              " '----------------------------------------------------------------------------------------------------']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def selection_par_index(fichier, valeur_recherchee):\n",
        "    index = creation_index_unique(fichier)\n",
        "    p, i = index[str(valeur_recherchee)]\n",
        "    return lecture_tuple(fichier, p, i)\n",
        "\n",
        "selection_par_index(DATA,s)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afvN2LWhJs0V"
      },
      "source": [
        "## Index range scan\n",
        "Accès pour rechercher les tuples dont le 1er attribut a une valeur comprise dans une intervalle donné"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "EGEO1PheSEdT"
      },
      "outputs": [],
      "source": [
        "def selection_par_index_plage(fichier, borne_inf, borne_sup):\n",
        "    index = creation_index_unique(fichier)\n",
        "    for k in index:\n",
        "        if borne_inf <= int(k) <= borne_sup:\n",
        "            p, i = index[k]\n",
        "            print(lecture_tuple(fichier, p, i))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEKExgGfKRUs"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7Rjm99DrKR8t"
      },
      "source": [
        "# Mise à jour de données\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7np5NI8OKK6z"
      },
      "source": [
        "## Sélectionner un tuple et modifier un de ses attributs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCRwCGlwKlEK"
      },
      "outputs": [],
      "source": [
        "def selection_tuple_par_index_modif_att(fichier, valeur_recherchee, att_modif, valeur_modif):\n",
        "    tp = selection_par_index(fichier, valeur_recherchee)\n",
        "    tp[att_modif] = valeur_modif\n",
        "    num_page = filtrer_fichier_par_pages(fichier, tp[0])\n",
        "    with open(page_dir_name(fichier) + f\"/page{num_page}\", \"r+\") as fp:\n",
        "        fp.write(tp)\n",
        "        fp.seek"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8zAZws5_KaL8"
      },
      "source": [
        "## Modifier l'index en conséquence lorsque l'attibut modifié est indexé\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_dcGN_dKaya"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as_W7xmOKc3l"
      },
      "source": [
        "# Persistence\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy8NE3x5KgLj"
      },
      "source": [
        "## Stocker un index (dans plusieurs pages) pour le reconstruire plus rapidement\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqSClCOgKl6a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzDPXcGzKjKU"
      },
      "source": [
        "## Adapter en conséquence les opérations de modification de l'index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9mXqJeFKmUE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:41:22) [Clang 13.0.1 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
